"""
üß† REAL MACHINE LEARNING SYSTEM FOR CRYPTO TRADING
===================================================

–†–µ–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å:
- Feature Engineering (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
- Online Learning (–æ–±—É—á–µ–Ω–∏–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏)
- Multi-objective Optimization (–Ω–µ —Ç–æ–ª—å–∫–æ PnL)
- Ensemble Methods (–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π)
- Contextual Learning (—É—á–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π)
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timezone, timedelta
from collections import deque
import json
import logging
from pathlib import Path

# ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.linear_model import SGDRegressor, LogisticRegression
    from sklearn.preprocessing import StandardScaler, RobustScaler
    from sklearn.metrics import mean_squared_error, classification_report
    from sklearn.model_selection import train_test_split
    import joblib
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class MarketContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä—ã–Ω–∫–∞ –≤–æ –≤—Ä–µ–º—è —Å–¥–µ–ª–∫–∏"""
    timestamp: datetime
    symbol: str
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    rsi_14: float
    rsi_7: float
    macd: float
    macd_signal: float
    bb_position: float  # –ü–æ–∑–∏—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ Bollinger Bands
    sma_20: float
    ema_50: float
    atr_14: float
    volume_ratio: float  # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –æ–±—ä–µ–º–∞ –∫ —Å—Ä–µ–¥–Ω–µ–º—É
    
    # –†—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
    volatility_percentile: float  # –ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (0-100)
    trend_strength: float  # –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞
    market_regime: str  # "trending", "ranging", "volatile"
    fear_greed_index: int
    btc_dominance: float
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
    hour_of_day: int
    day_of_week: int
    session: str  # "asian", "european", "american"
    
    # –¶–µ–Ω–æ–≤—ã–µ —É—Ä–æ–≤–Ω–∏
    support_distance: float  # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (%)
    resistance_distance: float  # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è (%)
    
    # –°–ø—Ä–µ–¥—ã –∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    bid_ask_spread: float
    order_book_imbalance: float

@dataclass
class TradeOutcome:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    trade_id: str
    pnl: float
    pnl_pct: float
    hold_time_minutes: float
    exit_reason: str
    
    # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    sharpe_ratio: float
    max_favorable_excursion: float  # MFE
    max_adverse_excursion: float   # MAE
    win_probability: float  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ –Ω–∞ –º–æ–º–µ–Ω—Ç –≤—Ö–æ–¥–∞
    
    # –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
    stress_level: float  # –£—Ä–æ–≤–µ–Ω—å "—Å—Ç—Ä–µ—Å—Å–∞" –ø–æ–∑–∏—Ü–∏–∏
    confidence_decay: float  # –ö–∞–∫ –º–µ–Ω—è–ª–∞—Å—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

@dataclass
class MLFeatures:
    """–ù–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π"""
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    rsi_momentum: float
    macd_divergence: float
    volume_surge: float
    price_momentum: float
    volatility_regime: float
    
    # –†—ã–Ω–æ—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    market_stress: float
    trend_alignment: float
    support_strength: float
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    session_volatility: float
    day_performance: float
    
    # –ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏
    signal_confluence: float
    historical_accuracy: float

class OnlineLearningModel:
    """–ú–æ–¥–µ–ª—å –æ–Ω–ª–∞–π–Ω-–æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, name: str):
        self.name = name
        self.model = SGDRegressor(
            learning_rate='adaptive',
            eta0=0.01,
            max_iter=1000,
            tol=1e-3
        ) if ML_AVAILABLE else None
        self.scaler = RobustScaler() if ML_AVAILABLE else None
        self.is_fitted = False
        self.samples_seen = 0
        
    def partial_fit(self, X: np.ndarray, y: np.ndarray):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if not ML_AVAILABLE:
            return
            
        try:
            if not self.is_fitted:
                # –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
                X_scaled = self.scaler.fit_transform(X)
                self.model.fit(X_scaled, y)
                self.is_fitted = True
            else:
                # –û–Ω–ª–∞–π–Ω –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
                X_scaled = self.scaler.transform(X)
                self.model.partial_fit(X_scaled, y)
                
            self.samples_seen += len(X)
            logger.debug(f"üß† [ML_{self.name}] Updated with {len(X)} samples, total: {self.samples_seen}")
            
        except Exception as e:
            logger.error(f"‚ùå [ML_{self.name}] Training error: {e}")
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
        if not ML_AVAILABLE or not self.is_fitted:
            return np.zeros(len(X))
            
        try:
            X_scaled = self.scaler.transform(X)
            return self.model.predict(X_scaled)
        except Exception as e:
            logger.error(f"‚ùå [ML_{self.name}] Prediction error: {e}")
            return np.zeros(len(X))

class AdvancedMLLearningSystem:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, config):
        self.config = config
        self.data_dir = Path("ml_learning_data")
        self.data_dir.mkdir(exist_ok=True)
        
        # –ò—Å—Ç–æ—Ä–∏—è –¥–∞–Ω–Ω—ã—Ö
        self.market_contexts = deque(maxlen=10000)
        self.trade_outcomes = deque(maxlen=10000)
        self.feature_history = deque(maxlen=5000)
        
        # ML –º–æ–¥–µ–ª–∏
        self.models = {
            'pnl_predictor': OnlineLearningModel('PnL'),
            'win_probability': OnlineLearningModel('WinProb'),
            'hold_time_predictor': OnlineLearningModel('HoldTime'),
            'risk_estimator': OnlineLearningModel('Risk')
        }
        
        # Ensemble –º–æ–¥–µ–ª–∏ (–¥–ª—è –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π)
        self.ensemble_models = {}
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.model_performance = {name: [] for name in self.models.keys()}
        
        logger.info("üß† [ADVANCED_ML] System initialized")
        self._load_historical_data()
    
    def extract_features(self, market_context: MarketContext, 
                        signal_strength: float, 
                        recent_performance: Dict) -> MLFeatures:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏"""
        
        try:
            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            rsi_momentum = (market_context.rsi_14 - 50) / 50  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π RSI
            macd_divergence = market_context.macd - market_context.macd_signal
            volume_surge = max(0, market_context.volume_ratio - 1)  # –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –æ–±—ä–µ–º–∞
            
            # –¶–µ–Ω–æ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
            price_momentum = (market_context.ema_50 - market_context.sma_20) / market_context.sma_20
            volatility_regime = market_context.volatility_percentile / 100
            
            # –†—ã–Ω–æ—á–Ω—ã–π —Å—Ç—Ä–µ—Å—Å
            market_stress = (100 - market_context.fear_greed_index) / 100
            
            # –¢—Ä–µ–Ω–¥
            trend_alignment = market_context.trend_strength * (1 if price_momentum > 0 else -1)
            
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ
            support_strength = 1 / (1 + market_context.support_distance)
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
            session_multiplier = {
                'american': 1.2,  # –í—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                'european': 1.0,
                'asian': 0.8      # –ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            }.get(market_context.session, 1.0)
            
            session_volatility = volatility_regime * session_multiplier
            
            # –î–Ω–µ–≤–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            day_performance = recent_performance.get('today_pnl_pct', 0) / 100
            
            # –ú–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏
            signal_confluence = signal_strength  # –ö–∞–∫ –º–Ω–æ–≥–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å–æ–≥–ª–∞—Å–Ω—ã
            historical_accuracy = recent_performance.get('recent_accuracy', 0.5)
            
            return MLFeatures(
                rsi_momentum=rsi_momentum,
                macd_divergence=macd_divergence,
                volume_surge=volume_surge,
                price_momentum=price_momentum,
                volatility_regime=volatility_regime,
                market_stress=market_stress,
                trend_alignment=trend_alignment,
                support_strength=support_strength,
                session_volatility=session_volatility,
                day_performance=day_performance,
                signal_confluence=signal_confluence,
                historical_accuracy=historical_accuracy
            )
            
        except Exception as e:
            logger.error(f"‚ùå [FEATURE_EXTRACTION] Error: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return MLFeatures(**{field: 0.0 for field in MLFeatures.__annotations__})
    
    async def predict_trade_outcome(self, market_context: MarketContext, 
                                  signal_strength: float,
                                  recent_performance: Dict) -> Dict[str, float]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏ –ø–µ—Ä–µ–¥ –≤—Ö–æ–¥–æ–º"""
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features = self.extract_features(market_context, signal_strength, recent_performance)
            feature_array = np.array([list(asdict(features).values())])
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
            predictions = {}
            
            for name, model in self.models.items():
                if model.is_fitted:
                    pred = model.predict(feature_array)[0]
                    predictions[name] = float(pred)
                else:
                    predictions[name] = 0.0
            
            # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            prediction_confidence = min(1.0, max(0.1, 
                sum(model.samples_seen for model in self.models.values()) / 1000
            ))
            
            result = {
                'expected_pnl_pct': predictions.get('pnl_predictor', 0.0),
                'win_probability': max(0.1, min(0.9, predictions.get('win_probability', 0.5))),
                'expected_hold_time': max(5, predictions.get('hold_time_predictor', 30)),  # –º–∏–Ω—É—Ç—ã
                'risk_score': predictions.get('risk_estimator', 0.5),
                'prediction_confidence': prediction_confidence,
                'feature_importance': self._get_feature_importance()
            }
            
            logger.info(f"üéØ [ML_PREDICTION] Expected: {result['expected_pnl_pct']:+.2f}% PnL, "
                       f"{result['win_probability']:.0%} win prob, {prediction_confidence:.2f} confidence")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [ML_PREDICTION] Error: {e}")
            return {
                'expected_pnl_pct': 0.0,
                'win_probability': 0.5,
                'expected_hold_time': 30.0,
                'risk_score': 0.5,
                'prediction_confidence': 0.0,
                'feature_importance': {}
            }
    
    async def learn_from_trade(self, market_context: MarketContext,
                             trade_outcome: TradeOutcome,
                             signal_strength: float,
                             recent_performance: Dict):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–π —Å–¥–µ–ª–∫–µ"""
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features = self.extract_features(market_context, signal_strength, recent_performance)
            feature_array = np.array([list(asdict(features).values())])
            
            # –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            targets = {
                'pnl_predictor': trade_outcome.pnl_pct,
                'win_probability': 1.0 if trade_outcome.pnl > 0 else 0.0,
                'hold_time_predictor': trade_outcome.hold_time_minutes,
                'risk_estimator': trade_outcome.max_adverse_excursion
            }
            
            # –û–±—É—á–∞–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏
            for name, target in targets.items():
                if name in self.models:
                    self.models[name].partial_fit(feature_array, np.array([target]))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            self.market_contexts.append(market_context)
            self.trade_outcomes.append(trade_outcome)
            self.feature_history.append(features)
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π
            if len(self.trade_outcomes) % 50 == 0:
                await self._evaluate_model_performance()
            
            logger.info(f"üß† [ML_LEARNING] Learned from trade: {trade_outcome.pnl_pct:+.2f}% PnL")
            
        except Exception as e:
            logger.error(f"‚ùå [ML_LEARNING] Error: {e}")
    
    async def get_intelligent_recommendations(self, current_market: MarketContext,
                                            recent_performance: Dict) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç AI —Å–∏—Å—Ç–µ–º—ã"""
        
        try:
            if not self.models['pnl_predictor'].is_fitted:
                return {'confidence': 0.0, 'recommendations': []}
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            features = self.extract_features(current_market, 1.0, recent_performance)
            feature_array = np.array([list(asdict(features).values())])
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            expected_pnl = self.models['pnl_predictor'].predict(feature_array)[0]
            win_prob = self.models['win_probability'].predict(feature_array)[0]
            risk_score = self.models['risk_estimator'].predict(feature_array)[0]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = []
            
            if expected_pnl > 0.5 and win_prob > 0.6:
                recommendations.append({
                    'action': 'increase_position_size',
                    'confidence': min(0.9, win_prob),
                    'reason': f'High win probability ({win_prob:.1%}) and positive expected return'
                })
            
            if risk_score > 0.7:
                recommendations.append({
                    'action': 'tighten_stop_loss',
                    'confidence': 0.8,
                    'reason': f'High risk environment detected (score: {risk_score:.2f})'
                })
            
            if features.volatility_regime > 0.8:
                recommendations.append({
                    'action': 'reduce_exposure',
                    'confidence': 0.7,
                    'reason': 'High volatility regime - reduce risk'
                })
            
            if features.trend_alignment > 0.5 and features.support_strength > 0.7:
                recommendations.append({
                    'action': 'extend_targets',
                    'confidence': 0.6,
                    'reason': 'Strong trend with solid support - ride the momentum'
                })
            
            confidence = min(1.0, sum(model.samples_seen for model in self.models.values()) / 2000)
            
            return {
                'confidence': confidence,
                'expected_pnl': expected_pnl,
                'win_probability': win_prob,
                'risk_score': risk_score,
                'recommendations': recommendations,
                'market_regime': current_market.market_regime,
                'feature_summary': {
                    'trend_strength': features.trend_alignment,
                    'volatility': features.volatility_regime,
                    'market_stress': features.market_stress
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå [ML_RECOMMENDATIONS] Error: {e}")
            return {'confidence': 0.0, 'recommendations': []}
    
    def _get_feature_importance(self) -> Dict[str, float]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        try:
            if not ML_AVAILABLE or not self.models['pnl_predictor'].is_fitted:
                return {}
            
            # –î–ª—è SGD –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∫–∞–∫ –≤–∞–∂–Ω–æ—Å—Ç—å
            coef = self.models['pnl_predictor'].model.coef_
            feature_names = list(MLFeatures.__annotations__.keys())
            
            importance = {}
            for i, name in enumerate(feature_names):
                if i < len(coef):
                    importance[name] = abs(float(coef[i]))
            
            return importance
            
        except Exception as e:
            logger.error(f"‚ùå [FEATURE_IMPORTANCE] Error: {e}")
            return {}
    
    async def _evaluate_model_performance(self):
        """–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π"""
        try:
            if len(self.trade_outcomes) < 30:
                return
            
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–¥–µ–ª–æ–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
            recent_outcomes = list(self.trade_outcomes)[-50:]
            recent_features = list(self.feature_history)[-50:]
            
            if len(recent_features) != len(recent_outcomes):
                return
            
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏
            X = np.array([list(asdict(f).values()) for f in recent_features])
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
            for name, model in self.models.items():
                if not model.is_fitted:
                    continue
                
                if name == 'pnl_predictor':
                    y_true = [outcome.pnl_pct for outcome in recent_outcomes]
                elif name == 'win_probability':
                    y_true = [1.0 if outcome.pnl > 0 else 0.0 for outcome in recent_outcomes]
                elif name == 'hold_time_predictor':
                    y_true = [outcome.hold_time_minutes for outcome in recent_outcomes]
                else:
                    continue
                
                y_pred = model.predict(X)
                mse = mean_squared_error(y_true, y_pred)
                
                self.model_performance[name].append({
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'mse': float(mse),
                    'samples': len(y_true)
                })
                
                logger.info(f"üìä [ML_PERFORMANCE] {name}: MSE = {mse:.4f}")
            
        except Exception as e:
            logger.error(f"‚ùå [ML_EVALUATION] Error: {e}")
    
    def _load_historical_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            contexts_file = self.data_dir / "market_contexts.json"
            outcomes_file = self.data_dir / "trade_outcomes.json"
            
            if contexts_file.exists() and outcomes_file.exists():
                with open(contexts_file, 'r') as f:
                    contexts_data = json.load(f)
                
                with open(outcomes_file, 'r') as f:
                    outcomes_data = json.load(f)
                
                logger.info(f"üß† [ML_LOAD] Loaded {len(contexts_data)} historical contexts")
                
        except Exception as e:
            logger.error(f"‚ùå [ML_LOAD] Error loading historical data: {e}")
    
    def save_data(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ ML —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã —Ä—ã–Ω–∫–∞
            contexts_data = []
            for context in self.market_contexts:
                contexts_data.append(asdict(context))
            
            with open(self.data_dir / "market_contexts.json", 'w') as f:
                json.dump(contexts_data, f, indent=2, default=str)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–¥–µ–ª–æ–∫
            outcomes_data = []
            for outcome in self.trade_outcomes:
                outcomes_data.append(asdict(outcome))
            
            with open(self.data_dir / "trade_outcomes.json", 'w') as f:
                json.dump(outcomes_data, f, indent=2, default=str)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏
            if ML_AVAILABLE:
                for name, model in self.models.items():
                    if model.is_fitted:
                        joblib.dump(model.model, self.data_dir / f"{name}_model.pkl")
                        joblib.dump(model.scaler, self.data_dir / f"{name}_scaler.pkl")
            
            logger.info(f"üíæ [ML_SAVE] Saved ML data: {len(self.market_contexts)} contexts, "
                       f"{len(self.trade_outcomes)} outcomes")
            
        except Exception as e:
            logger.error(f"‚ùå [ML_SAVE] Error: {e}")